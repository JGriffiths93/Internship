{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fa298f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting bs4\n",
      "  Downloading bs4-0.0.1.tar.gz (1.1 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (from bs4) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4->bs4) (2.3.1)\n",
      "Building wheels for collected packages: bs4\n",
      "  Building wheel for bs4 (setup.py): started\n",
      "  Building wheel for bs4 (setup.py): finished with status 'done'\n",
      "  Created wheel for bs4: filename=bs4-0.0.1-py3-none-any.whl size=1257 sha256=8133fc29834093c65c1da379b9a4c738e017550fe9599188ece38a570f6da48d\n",
      "  Stored in directory: c:\\users\\marneljun\\appdata\\local\\pip\\cache\\wheels\\73\\2b\\cb\\099980278a0c9a3e57ff1a89875ec07bfa0b6fcbebb9a8cad3\n",
      "Successfully built bs4\n",
      "Installing collected packages: bs4\n",
      "Successfully installed bs4-0.0.1\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (2.28.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (3.3)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (1.26.11)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests) (2022.9.14)\n"
     ]
    }
   ],
   "source": [
    "# Install all required libraries\n",
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38e50149",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "from bs4 import BeautifulSoup,SoupStrainer\n",
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b259d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2af352fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h1 Explore 300,000+ jobs',\n",
       " 'h2 Cool Places to Work',\n",
       " 'h2 Top Companies Hiring',\n",
       " 'h2 Be An Early Applicant',\n",
       " 'h2 Req. for the Technology Analyst IT Services',\n",
       " 'h2 we have post for the IT Delivery',\n",
       " 'h2 We need  IT Delivery',\n",
       " 'h2 We need Technical Operations Associate',\n",
       " 'h2 We need Process Lead',\n",
       " 'h2 We Needs for Senior Technical Process Executive',\n",
       " 'h2 Remote Jobs',\n",
       " 'h2 Big Data Engineer',\n",
       " 'h2 Java Back-end Developer',\n",
       " 'h2 Big DataEngineer- Bangalore',\n",
       " 'h2 Cluster Head - Chandigarh',\n",
       " 'h2 Test Data Management (Delphix)',\n",
       " 'h2 Test Data Management (Delphix)',\n",
       " 'h2 Walkin Jobs',\n",
       " 'h2 Branch Relationship Manager',\n",
       " 'h2 It Recruiter',\n",
       " 'h2 Gold Loan Officer',\n",
       " 'h2 Business Development',\n",
       " 'h2 Hr Recruiter OR Senior recruiter',\n",
       " 'h2 Acquisition Manager- Digital Sales',\n",
       " 'h2 Domain Jobs',\n",
       " 'h2 DevOps Engineer  West Bengal',\n",
       " 'h2 DevOps Engineer Kolkata',\n",
       " 'h2 DevOps Engineer Gwalior',\n",
       " 'h2 DevOps Engineer Hyderabad',\n",
       " 'h2 DevOps Engineer Chennai',\n",
       " 'h2 DevOps Engineer Nagpur',\n",
       " 'h2 DevOps Engineer  West Bengal',\n",
       " 'h2 DevOps Engineer Kolkata',\n",
       " 'h2 DevOps Engineer Gwalior',\n",
       " 'h2 DevOps Engineer Hyderabad',\n",
       " 'h2 DevOps Engineer Chennai',\n",
       " 'h2 DevOps Engineer Nagpur',\n",
       " 'h2 DevOps Engineer  West Bengal',\n",
       " 'h2 DevOps Engineer Kolkata',\n",
       " 'h2 DevOps Engineer Gwalior',\n",
       " 'h2 DevOps Engineer Hyderabad',\n",
       " 'h2 DevOps Engineer Chennai',\n",
       " 'h2 DevOps Engineer Nagpur',\n",
       " 'h2 DevOps Engineer  West Bengal',\n",
       " 'h2 DevOps Engineer Kolkata',\n",
       " 'h2 DevOps Engineer Gwalior',\n",
       " 'h2 DevOps Engineer Hyderabad',\n",
       " 'h2 DevOps Engineer Chennai',\n",
       " 'h2 DevOps Engineer Nagpur',\n",
       " 'h2 DevOps Engineer  West Bengal',\n",
       " 'h2 DevOps Engineer Kolkata',\n",
       " 'h2 DevOps Engineer Gwalior',\n",
       " 'h2 DevOps Engineer Hyderabad',\n",
       " 'h2 DevOps Engineer Chennai',\n",
       " 'h2 DevOps Engineer Nagpur',\n",
       " 'h2 DevOps Engineer  West Bengal',\n",
       " 'h2 DevOps Engineer Kolkata',\n",
       " 'h2 DevOps Engineer Gwalior',\n",
       " 'h2 DevOps Engineer Hyderabad',\n",
       " 'h2 DevOps Engineer Chennai',\n",
       " 'h2 DevOps Engineer Nagpur',\n",
       " 'h2 DevOps Engineer  West Bengal',\n",
       " 'h2 DevOps Engineer Kolkata',\n",
       " 'h2 DevOps Engineer Gwalior',\n",
       " 'h2 DevOps Engineer Hyderabad',\n",
       " 'h2 DevOps Engineer Chennai',\n",
       " 'h2 DevOps Engineer Nagpur',\n",
       " 'h2 Hackathons',\n",
       " 'h2 Matrix Marketers Hiring Challenge',\n",
       " 'h2 Armia system Hiring Challenge',\n",
       " 'h2 Are You an Employer?',\n",
       " 'h2 Explore Our Premium Services',\n",
       " 'h2 Popular Courses',\n",
       " 'h3 Backend Developer in Java',\n",
       " 'h3 Backend Developer in Python',\n",
       " 'h3 Backend Developer in Node.js',\n",
       " 'h3 Backend Developer in .Net',\n",
       " 'h3 Frontend Developer in React.js',\n",
       " 'h3 Frontend Developer in Angular.js',\n",
       " 'h2 Latest from Blog']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Send get request to the webpage server to get the source code of the page\n",
    "url='https://www.shine.com/'\n",
    "page = requests.get(url)\n",
    "# page content\n",
    "soup = BeautifulSoup(page.content)\n",
    "# Scrape the Header tag\n",
    "header_tags=[]\n",
    "\n",
    "for header in soup.find_all([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\",\"h6\"]):\n",
    "    header_tags.append(header.name+\" \"+header.text.strip())\n",
    "\n",
    "#print all header_tags\n",
    "header_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85fc4d49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['h1 Data Analyst Jobs in Bangalore',\n",
       " 'h2 Project Coordinator (Data Analyst)',\n",
       " 'h2 Data Analyst - Java/Python',\n",
       " 'h2 Hiring For Data Analyst',\n",
       " 'h2 Senior Data Analyst',\n",
       " 'h2 Data Analyst',\n",
       " 'h2 Data Analyst Urgent Recruiment',\n",
       " 'h2 How relevant did you find the job search results ?',\n",
       " 'h2 Apply Now   a Data Analyst',\n",
       " 'h2 Apply Now   Data Analyst',\n",
       " 'h2 Needed for   Data Analyst',\n",
       " 'h2 Urgently need a Data Analyst',\n",
       " 'h2 Require now   Data Analyst',\n",
       " 'h2 Data Analyst',\n",
       " 'h2 Project Coordinator (Data Analyst)',\n",
       " 'h2 Data Analyst in Bpo',\n",
       " 'h2 Clinical Data Analyst',\n",
       " 'h2 Data Analyst',\n",
       " 'h2 Data Analyst',\n",
       " 'h2 opening data analyst -Bangalore',\n",
       " 'h2 Data Analyst',\n",
       " 'h2 Data Analyst - Bangalore',\n",
       " 'h2 Project Coordinator (Data Analyst)',\n",
       " 'h2 Project Coordinator (Data Analyst)',\n",
       " 'h3 Job Details',\n",
       " 'h4 Other Details',\n",
       " 'h3 Key Skills',\n",
       " 'h3 Recruiter Details',\n",
       " 'h3 Job Seekers',\n",
       " 'h3 Employers',\n",
       " 'h3 Partner Sites',\n",
       " 'h3 Contact Us']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Send get request to the webpage server to get the source code of the page\n",
    "url='https://www.shine.com/job-search/data-analyst-jobs-in-bangalore?q=Data%20Analyst%2C%20&loc=Bangalore'\n",
    "page = requests.get(url)\n",
    "# page content\n",
    "soup = BeautifulSoup(page.content)\n",
    "# Scrape the Header tag\n",
    "header_tags=[]\n",
    "\n",
    "for header in soup.find_all([\"h1\",\"h2\",\"h3\",\"h4\",\"h5\",\"h6\"]):\n",
    "    header_tags.append(header.name+\" \"+header.text.strip())\n",
    "\n",
    "#print all header_tags\n",
    "header_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f93f1938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Job Title, Job Location, Company Name, Experience Required]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Send url request and download page content\n",
    "data_analyst_soup=BeautifulSoup(requests.get(\"https://www.shine.com/job-search/data-analyst-jobs-in-bangalore?q=Data%20Analyst%2C%20&loc=Bangalore\").content,\"html.parser\")\n",
    "response = requests.get(\"https://www.shine.com/job-search/data-analyst-jobs-in-bangalore?q=Data%20Analyst%2C%20&loc=Bangalore\")\n",
    "# Scrape data for first 10 job vacancies\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "job_vacancies = data_analyst_soup.find_all('section', class_='s-plain-list-item')\n",
    "\n",
    "job_data = []\n",
    "for job in job_vacancies[:10]:\n",
    "    job_title = job.find('h3', class_='s-title').text.strip()\n",
    "    job_location = job.find('span', itemprop='addressLocality').text.strip()\n",
    "    company_name = job.find(class_='s-txt-cpn').text.strip()\n",
    "    experience_required = job.find(class_='s-txt-exp').text.strip()\n",
    "    job_data.append([job_title, job_location, company_name, experience_required])\n",
    "\n",
    "# Make data frame of top 10 jobs\n",
    "job_details = pd.DataFrame(job_data, columns=[\"Job Title\", \"Job Location\", \"Company Name\", \"Experience Required\"])\n",
    "print(job_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b21676de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [Job Title, Job Location, Company Name, Experience Required]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Send url request and download page content\n",
    "url = \"https://www.shine.com/job-search/data-scientist-jobs-in-delhi-ncr-region?q=Data%20Scientist,%20&loc=Delhi-ncr%20Region&fsalary=1\"\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "# Scrape data for first 10 job vacancies\n",
    "job_vacancies = soup.find_all('section', class_='s-plain-list-item')\n",
    "\n",
    "job_data = []\n",
    "for job in job_vacancies[:10]:\n",
    "    job_title = job.find('h3', class_='s-title').text.strip()\n",
    "    job_location = job.find('span', itemprop='addressLocality').text.strip()\n",
    "    company_name = job.find(class_='s-txt-cpn').text.strip()\n",
    "    experience_required = job.find(class_='s-txt-exp').text.strip()\n",
    "    job_data.append([job_title, job_location, company_name, experience_required])\n",
    "\n",
    "# Make data frame of top 10 jobs\n",
    "job_details = pd.DataFrame(job_data, columns=[\"Job Title\", \"Job Location\", \"Company Name\", \"Experience Required\"])\n",
    "print(job_details)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802d9d7c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
